---
title: "Biases in online labor markets: A systematic review"
author: "Gerit Wagner, Julian Prester, Roman Lukyanenko, Guy Paré"
bibliography: references.bib
format:
  html:
    code-fold: true
    code-summary: "Show the code"
    css: styles.css
    include-after-body:
      - assets/popup-handler.html
execute:
  freeze: auto
---

::: {.callout-important title="TODO" collapse=true}
The data repository (colrev project) is currently stored separately: [fs-ise/C5-DM-vignette](https://github.com/fs-ise/C5-DM-vignette){target=_blank}.
Before submission, the quarto manuscript (vignette) will be added as the last commit on top of the colrev projet (it should be available in the `data/data/paper.md`).
At the moment, it will be kept separately to allow for forced-push updaes.

**TODO**:

- Consider switching the framework illustration (process left, principles on the right?)
- PRISMA chart is generated but needs to be tested properly
- Update links in this document
- Include vignette (screenshot?) in the paper
- Intro: refer to C5-DM framework and introduce annotations (5C)
:::


Building on the C5-DM framework for data management in literature reviews [@WagnerEtAl2026], this vignette illustrates how data management principles can be implemented in an literature review.
The framework foregrounds data conceptualization, collection, curation, control, and consumption as foundational activities that shape the transparency, reliability, and reuse of literature review outcomes.
The vignette is organized into two complementary parts.
The middle column presents a systematic literature review following established reporting conventions.
The right column explains how the manuscript is internally grounded in explicit data management decisions aligned with the C5-DM framework, adding an interactive layer of annotations that makes these decisions visible.
The vignette thus serves as a concrete illustration of good data management practice in literature reviews—one that readers can follow directly in their own work while also sharpening their understanding of what to look for when evaluating other software solutions and data management approaches.

::: aside
::: {.callout-note title="5C-DM Framework"}
This column explains how the prinicples of the framework are implemented. ⬇️

<!-- Click on the buttons for an explanation. -->
:::
:::

## Plan

The review is conducted using a [shared GitHub repository](https://github.com/fs-ise/C5-DM-vignette){target=_blank}, which was be synchronized locally by the team.

::: aside
<a class="curate-pill"
   href="curate-info.html"
   rel="noopener noreferrer"
   data-popup="curatePopup"
   data-popup-width="900"
   data-popup-height="700">
  Curate: <span aria-hidden="true" class="curate-pill__detail">Storing data in a version-controlled folder. ↗</span>
</a>
:::

## Search

We specified search strategies for the DBLP and Crossref application programming interfaces (APIs)[^1] using the core keyword *microsourcing* and a set of semantically related synonyms.
We also reused samples from prior reviews [@WagnerPresterPare2021;@Fiers2023].
The resulting query formulations were systematically tabulated to document the conceptual scope of the search and to enable consistent execution across data sources (see @tbl-search-overview).

::: aside
<a class="curate-pill"
   href="consume-reuse-prior-review.html"
   rel="noopener noreferrer"
   data-popup="curatePopup"
   data-popup-width="900"
   data-popup-height="700">
  Consume: <span aria-hidden="true" class="curate-pill__detail">Reuse of prior review data. ↗</span>
</a>
:::

```{python}
#| output: asis
#| echo: false

import json
from pathlib import Path
from urllib.parse import quote

SEARCH_DIR = Path("/home/gerit/ownCloud/data/literature_reviews/LRDM/C5-DM-vignette/data/search")

def md_link(text: str, target_path: str) -> str:
    target_path_posix = Path(target_path).as_posix()
    url = target_path_posix
    return f"[{text}]({url})"


json_files = sorted(SEARCH_DIR.glob("*.json"))

rows = []
for jf in json_files:
    try:
        data = json.loads(jf.read_text(encoding="utf-8"))
    except Exception:
        continue

    label = (data.get("label") or jf.stem).strip()
    results_path = (data.get("search_results_path") or "").strip()

    # Render links in the same "data/search/..." style as in your manual table
    json_link_target = f"data/search/{jf.name}"
    search_strategy_cell = md_link(jf.name, json_link_target)

    search_results_cell = (
        md_link(Path(results_path).name, results_path)
        if results_path
        else ""
    )

    rows.append((label, search_strategy_cell, search_results_cell))

print("::: {#tbl-search-overview}")
print("Table: Overview of search strategies and results.\n")
print("| Source | Search strategy | Search results |")
print("|:--------|:-----------------|:----------------|")
for s, strat, res in rows:
  print(f"| {s} | {strat} | {res} |")
print("\n:::")
```

The search strategie are stored in JSON format together with the raw data files in the [data/search](https://github.com/fs-ise/C5-DM-vignette/tree/main/data/search){target=_blank} directory, in line with the standard of @HaddawayRethlefsenDaviesEtAl2022.

::: aside
<a class="curate-pill"
   href="conceptualize-info.html"
   rel="noopener noreferrer"
   data-popup="curatePopup"
   data-popup-width="900"
   data-popup-height="700">
  Conceptualize: <span aria-hidden="true" class="curate-pill__detail">Keeping track of raw and primary records. ↗</span>
</a>
:::

::: aside
<a class="curate-pill"
   href="control-standard-formats.html"
   rel="noopener noreferrer"
   data-popup="curatePopup"
   data-popup-width="900"
   data-popup-height="700">
  Control: <span aria-hidden="true" class="curate-pill__detail">Use of standard file formats. ↗</span>
</a>

TODO: mention BibTex and JSON.
:::

::: aside
<a class="curate-pill"
   href="collect-search-strategy-design.html"
   rel="noopener noreferrer"
   data-popup="curatePopup"
   data-popup-width="900"
   data-popup-height="700">
  Collect: <span aria-hidden="true" class="curate-pill__detail">Search strategy design. ↗</span>
</a>
:::

::: aside
<a class="curate-pill"
   href="collect-transparency-access.html"
   rel="noopener noreferrer"
   data-popup="curatePopup"
   data-popup-width="900"
   data-popup-height="700">
  Collect: <span aria-hidden="true" class="curate-pill__detail">Transparency on data coverage/access (??). ↗</span>
</a>
:::

::: {.callout-note title="TODO" collapse=true}
- Search-query was used to validate syntactic correctness and ...
- scope (????)
:::

## Dedupe

Metadata was prepared using CoLRev and extensions (see [prep commit](https://github.com/fs-ise/C5-DM-vignette/commit/051e115fff389f209afb9a4fbe77e6a33271264c){target=_blank}).

Deduplication was done using BibDedupe [@Wagner2024].
Deduplication changes are in [dedupe commit](https://github.com/fs-ise/C5-DM-vignette/commit/c22178d10fb90954d681f428fc5b08c72b5e6d48){target=_blank}.

::: aside
<a class="curate-pill"
   href="collect-preparation-procedures.html"
   rel="noopener noreferrer"
   data-popup="curatePopup"
   data-popup-width="900"
   data-popup-height="700">
  Collect: <span aria-hidden="true" class="curate-pill__detail">Data preparation procedures. ↗</span>
</a>
:::

<!--
Dedupe changes were validated using the max-diff strategy (`colrev validate XXXX`).
Preparation changes were validated using the max-diff strategy (`colrev validate XXXX`).
-->

## Prescreen

::: {.callout-note title="Manual task"}
**Trigger:** `records_deduped.bib` updated  
**Responsible:** Two independent coders (GW anmd JP)  
**Protocol:** PRISMA TA screening rules (see `protocol/screening.md`)  
**Expected output:** `records_screened.bib`
**History filter:** TODO (e.g., "prescreen" in commit title)
:::


::: aside
<a class="curate-pill"
   href="control-evaluating-reliability.html"
   rel="noopener noreferrer"
   data-popup="curatePopup"
   data-popup-width="900"
   data-popup-height="700">
  Control: <span aria-hidden="true" class="curate-pill__detail">Evaluating the reliability of AI contributions. ↗</span>
</a>
:::

::: {.callout-note title="TODO" collapse=true}
Replace this figure:

![Data structures](figures/illustration-lr-transparency.png)

- For prescreening, we tested the new [llm-prescreener](temp_file.txt){target=_blank} in [ref](temp_file.txt){target=_blank}. Comparison with prescreening decisions of GW showed low reliability with the llm-prescreener (command + kappa). Results were therefore reverted ([ref](temp_file.txt)) and a fully manual prescreen was implemented.

Note: this could also be done in a separate branch, or the changes could be undone using a hard git reset.

- Screen: fulltext documents were shared in a protected drive (link to Dropbox)
:::

## Data extraction

In line with the methodology of systematic reviews [**REFS**], we selected structured data forms to extract evidence from the studies (a preliminary coding scheme is [TODO](temp_file.txt){target=_blank} and the pilot coding [TODO](temp_file.txt){target=_blank}).
Data is extracted [here](data).

::: {.callout-note title="Manual task"}
**Trigger:** `records_deduped.bib` updated  
**Responsible:** Two independent coders (GW anmd JP)  
**Protocol:** data extraction form and protocol (see `protocol/data_extraction.md`)  
**Expected output:** `extracted_evidence.yaml`
**History filter:** TODO (e.g., "extract" in commit title)
:::

::: aside
<a class="curate-pill"
   href="curate-structure-fit.html"
   rel="noopener noreferrer"
   data-popup="curatePopup"
   data-popup-width="900"
   data-popup-height="700">
  Curate: <span aria-hidden="true" class="curate-pill__detail">Aligning data structure and methodology. ↗</span>
</a>
:::

::: aside
<a class="curate-pill"
   href="consume-non-automation.html"
   rel="noopener noreferrer"
   data-popup="curatePopup"
   data-popup-width="900"
   data-popup-height="700">
  Consume: <span aria-hidden="true" class="curate-pill__detail">Understand when automated extraction is not appropriate. ↗</span>
</a>
:::

## Synthesis

The narrative synthesis is in the [paper document](https://github.com/fs-ise/C5-DM-vignette/blob/main/data/data/paper.md){target=_blank} in Markdown format, allowing for larger teams to work on the same document (similar to the [covid19-review](https://github.com/greenelab/covid19-review)).
The current status of the project is automatically updated with every change and reflected in the PRISMA chart [@PageMcKenzieBossuytEtAl2021]:

```{python}
#| label: fig-prisma
#| fig-cap: "PRISMA Flow Chart (generated by [python-prisma (TODO)](link))"

from py_prisma import plot_prisma_from_records

plot_prisma_from_records(records_path="Curate: data publishing/data/records.bib", show=True)

```

@tbl-evidence provides summary of extracted evidence.


```{python}
#| label: tbl-evidence
#| tbl-cap: "Table of evidence (generated from [TODO](link))"
#| echo: true
#| message: false
#| warning: false

from pathlib import Path
import yaml
import pandas as pd
import matplotlib.pyplot as plt

yaml_path = Path("data/evidence_platform_work_biases.yml")

with yaml_path.open("r", encoding="utf-8") as f:
    doc = yaml.safe_load(f)

df = pd.DataFrame(doc.get("papers", []))

cols = [
    "study_id", "citation_key", "year", "platform", "platform_type",
    "method", "data", "sample",
    "bias_type", "bias_mechanism",
    "outcome_affected", "evidence_level", "direction_of_bias",
    "key_result", "notes",
]
df = df[[c for c in cols if c in df.columns]]

df["year"] = pd.to_numeric(df.get("year"), errors="coerce").astype("Int64")
df = df.sort_values(["bias_type", "evidence_level", "year"], na_position="last").reset_index(drop=True)

compact_cols = [
    "citation_key", "platform_type", "bias_type", "evidence_level",
    "outcome_affected", "key_result"
]
df_compact = df[compact_cols].rename(columns={"citation_key": "study"})
df_compact
```

@fig-aggregated-evidence aggregates the evidence.

```{python}
#| label: fig-aggregated-evidence
#| fig-cap: "Aggregated evidence (generated from [TODO](link))"
#| echo: true
#| message: false
#| warning: false

weights = {
    "weak": 1,
    "moderate": 2,
    "moderate_to_strong": 3,
    "strong": 4
}

df_w = df.copy()
df_w["evidence_weight"] = df_w["evidence_level"].map(weights).fillna(0)

score = (
    df_w.groupby("bias_type")["evidence_weight"]
        .sum()
        .sort_values(ascending=False)
)

ax = score.plot(kind="barh", figsize=(8, 3))
ax.set_title("Weighted evidence score by bias type (higher = more/stronger evidence)")
ax.set_xlabel("Bias type")
ax.set_ylabel("Weighted score")
plt.tight_layout()
plt.show()

```

## Data availability

To make the review reusable, the data was published on GitHub under the [CC BY 4.0](https://github.com/fs-ise/C5-DM-vignette/blob/main/LICENSE.txt) license[^2].

::: aside
<a class="curate-pill"
   href="curate-data-publishing.html"
   rel="noopener noreferrer"
   data-popup="curatePopup"
   data-popup-width="900"
   data-popup-height="700">
  Curate: <span aria-hidden="true" class="curate-pill__detail">Enabling reuse through data sharing. ↗</span>
</a>
:::

::: aside
<a class="curate-pill"
   href="consume-licenses.html"
   rel="noopener noreferrer"
   data-popup="curatePopup"
   data-popup-width="900"
   data-popup-height="700">
  Consume: <span aria-hidden="true" class="curate-pill__detail">Selecting open licenses. ↗</span>
</a>
:::


[^1]: For the illustration, we relied on open-access API-searches, because licensing issues do not allow for publication of raw data exported from databases like WOS or EBSCO.
[^2]: Indexing in SYNERGY, SearchRXiv is planned once the review progresses beyond the *illustration* stages.

# References